{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3886"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install hf_transfer\n",
        "!export HF_HUB_ENABLE_HF_TRANSFER=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NHwItDH9gddl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    TextStreamer,\n",
        "    CLIPVisionModel,\n",
        "    CLIPImageProcessor,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from huggingface_hub import login, notebook_login\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ozhi5tPtgn0U"
      },
      "outputs": [],
      "source": [
        "def print_markdown(text: str):\n",
        "  return display(Markdown(text))\n",
        "model_id=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "998b2556aced48aba9ab08bb76f2e166",
            "7234d0f46f8a43a194c542f5446b4e6a",
            "9ac1a8b1bb264fc3b438a3984ed1a72e",
            "daadc7677b244b15a8f36db5fd9f31ae",
            "cdbc42c8132046f69c87c2e64aa496a1",
            "6d2f0b6757254b0ebb316a7786943476",
            "c970f6cdb0054e69bd86b4cb1987bafd",
            "c4d2dcc08a374677857f24b3dae098a6",
            "45512218c0954f0cb9547bf00dc494f6",
            "8a6ab6f09b8840a9b9bbfd895fd99f3a",
            "a4acb11c7c9548fab831a42cf0117d8e"
          ]
        },
        "id": "5xngXE5fgqdF",
        "outputId": "d5ce39d8-5475-4647-fcde-d73b862209e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7289b692e1c847258840495354b7d6f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/339 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-12:\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
            "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/_monitor.py\"\u001b[0m, line \u001b[35m84\u001b[0m, in \u001b[35mrun\u001b[0m\n",
            "    \u001b[31minstance.refresh\u001b[0m\u001b[1;31m(nolock=True)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/std.py\"\u001b[0m, line \u001b[35m1347\u001b[0m, in \u001b[35mrefresh\u001b[0m\n",
            "    \u001b[31mself.display\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/notebook.py\"\u001b[0m, line \u001b[35m171\u001b[0m, in \u001b[35mdisplay\u001b[0m\n",
            "    \u001b[1;31mrtext.value\u001b[0m = right\n",
            "    \u001b[1;31m^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/traitlets/traitlets.py\"\u001b[0m, line \u001b[35m716\u001b[0m, in \u001b[35m__set__\u001b[0m\n",
            "    \u001b[31mself.set\u001b[0m\u001b[1;31m(obj, value)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/traitlets/traitlets.py\"\u001b[0m, line \u001b[35m706\u001b[0m, in \u001b[35mset\u001b[0m\n",
            "    \u001b[31mobj._notify_trait\u001b[0m\u001b[1;31m(self.name, old_value, new_value)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/traitlets/traitlets.py\"\u001b[0m, line \u001b[35m1513\u001b[0m, in \u001b[35m_notify_trait\u001b[0m\n",
            "    \u001b[31mself.notify_change\u001b[0m\u001b[1;31m(\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
            "        \u001b[1;31mBunch(\u001b[0m\n",
            "        \u001b[1;31m^^^^^^\u001b[0m\n",
            "    ...<5 lines>...\n",
            "        \u001b[1;31m)\u001b[0m\n",
            "        \u001b[1;31m^\u001b[0m\n",
            "    \u001b[1;31m)\u001b[0m\n",
            "    \u001b[1;31m^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/ipywidgets/widgets/widget.py\"\u001b[0m, line \u001b[35m700\u001b[0m, in \u001b[35mnotify_change\u001b[0m\n",
            "    \u001b[31mself.send_state\u001b[0m\u001b[1;31m(key=name)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/ipywidgets/widgets/widget.py\"\u001b[0m, line \u001b[35m586\u001b[0m, in \u001b[35msend_state\u001b[0m\n",
            "    \u001b[31mself._send\u001b[0m\u001b[1;31m(msg, buffers=buffers)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/ipywidgets/widgets/widget.py\"\u001b[0m, line \u001b[35m825\u001b[0m, in \u001b[35m_send\u001b[0m\n",
            "    \u001b[31mself.comm.send\u001b[0m\u001b[1;31m(data=msg, buffers=buffers)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/comm/base_comm.py\"\u001b[0m, line \u001b[35m144\u001b[0m, in \u001b[35msend\u001b[0m\n",
            "    \u001b[31mself.publish_msg\u001b[0m\u001b[1;31m(\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
            "        \u001b[1;31m\"comm_msg\",\u001b[0m\n",
            "        \u001b[1;31m^^^^^^^^^^^\u001b[0m\n",
            "    ...<2 lines>...\n",
            "        \u001b[1;31mbuffers=buffers,\u001b[0m\n",
            "        \u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
            "    \u001b[1;31m)\u001b[0m\n",
            "    \u001b[1;31m^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/ipykernel/comm/comm.py\"\u001b[0m, line \u001b[35m42\u001b[0m, in \u001b[35mpublish_msg\u001b[0m\n",
            "    parent=\u001b[31mself.kernel.get_parent\u001b[0m\u001b[1;31m()\u001b[0m,\n",
            "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "  File \u001b[35m\"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/ipykernel/kernelbase.py\"\u001b[0m, line \u001b[35m797\u001b[0m, in \u001b[35mget_parent\u001b[0m\n",
            "    return \u001b[31mself._shell_parent.get\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "\u001b[1;35mLookupError\u001b[0m: \u001b[35m<ContextVar name='shell_parent' at 0x105a99300>\u001b[0m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# device = \"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# if torch.cuda.is_available():\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#   device = torch.device(\"cuda\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#   device = torch.device(\"cpu\")\u001b[39;00m\n\u001b[32m     17\u001b[39m torch.device(\u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m  \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msdpa\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m  \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantization_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m  \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m  \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m  \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_id)\n\u001b[32m     29\u001b[39m streamer = TextStreamer(tokenizer, skip_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:374\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    373\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    378\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    380\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/modeling_utils.py:4063\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4046\u001b[39m \u001b[38;5;66;03m# Finalize model weight initialization\u001b[39;00m\n\u001b[32m   4047\u001b[39m load_config = LoadStateDictConfig(\n\u001b[32m   4048\u001b[39m     pretrained_model_name_or_path=pretrained_model_name_or_path,\n\u001b[32m   4049\u001b[39m     ignore_mismatched_sizes=ignore_mismatched_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4061\u001b[39m     download_kwargs=download_kwargs,\n\u001b[32m   4062\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m4063\u001b[39m loading_info, disk_offload_index = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4064\u001b[39m loading_info = \u001b[38;5;28mcls\u001b[39m._finalize_model_loading(model, load_config, loading_info)\n\u001b[32m   4065\u001b[39m model.eval()  \u001b[38;5;66;03m# Set model in evaluation mode to deactivate Dropout modules by default\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/modeling_utils.py:4182\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(model, state_dict, checkpoint_files, load_config)\u001b[39m\n\u001b[32m   4179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNeither a state dict nor checkpoint files were found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4182\u001b[39m loading_info, disk_offload_index = \u001b[43mconvert_and_load_state_dict_in_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtp_plan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tp_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4190\u001b[39m \u001b[38;5;66;03m# finally close all opened file pointers\u001b[39;00m\n\u001b[32m   4191\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m all_pointer:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/core_model_loading.py:1192\u001b[39m, in \u001b[36mconvert_and_load_state_dict_in_model\u001b[39m\u001b[34m(model, state_dict, load_config, tp_plan, disk_offload_index)\u001b[39m\n\u001b[32m   1190\u001b[39m pbar.refresh()\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     realized_value = \u001b[43mmapping\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_param_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloading_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1199\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m target_name, param \u001b[38;5;129;01min\u001b[39;00m realized_value.items():\n\u001b[32m   1200\u001b[39m         param = param[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m param\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/core_model_loading.py:676\u001b[39m, in \u001b[36mWeightRenaming.convert\u001b[39m\u001b[34m(self, layer_name, model, config, hf_quantizer, loading_info)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quantization_operation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m log_conversion_errors(\n\u001b[32m    674\u001b[39m         layer_name, loading_info, (\u001b[38;5;28mlen\u001b[39m(collected_tensors), layer_name), \u001b[38;5;28mself\u001b[39m.quantization_operation\n\u001b[32m    675\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m         collected_tensors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquantization_operation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcollected_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource_patterns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_patterns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfull_layer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloading_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmissing_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloading_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collected_tensors\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/integrations/bitsandbytes.py:56\u001b[39m, in \u001b[36mBnb4bitQuantize.convert\u001b[39m\u001b[34m(self, input_dict, full_layer_name, model, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m     value = value.T\n\u001b[32m     55\u001b[39m old_value = model.get_parameter_or_buffer(full_layer_name)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m new_value = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mold_value\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m module._is_hf_initialized = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {full_layer_name: new_value}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/bitsandbytes/nn/modules.py:346\u001b[39m, in \u001b[36mParams4bit.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m device, dtype, non_blocking, _ = torch._C._nn._parse_to(*args, **kwargs)\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device.type != \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bnb_quantized:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/bitsandbytes/nn/modules.py:301\u001b[39m, in \u001b[36mParams4bit._quantize\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[32m    300\u001b[39m     w = \u001b[38;5;28mself\u001b[39m.data.contiguous().to(device)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     w_4bit, quant_state = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = w_4bit\n\u001b[32m    309\u001b[39m     \u001b[38;5;28mself\u001b[39m.quant_state = quant_state\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/bitsandbytes/functional.py:864\u001b[39m, in \u001b[36mquantize_4bit\u001b[39m\u001b[34m(A, absmax, out, blocksize, compress_statistics, quant_type, quant_storage)\u001b[39m\n\u001b[32m    860\u001b[39m     blocksize = \u001b[32m64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ROCM_WARP_SIZE_64 \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m128\u001b[39m\n\u001b[32m    862\u001b[39m input_shape = A.shape\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m _out, _absmax = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitsandbytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    871\u001b[39m code = get_4bit_type(quant_type, device=A.device)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compress_statistics:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/torch/_ops.py:819\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/torch/_compile.py:54\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     52\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py:1181\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m fx_traceback.annotate(\n\u001b[32m   1172\u001b[39m             {\n\u001b[32m   1173\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m_torchdynamo_disable\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1178\u001b[39m             }\n\u001b[32m   1179\u001b[39m         ):\n\u001b[32m   1180\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1183\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/torch/library.py:742\u001b[39m, in \u001b[36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_no_dynamo\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/bitsandbytes/backends/default/ops.py:250\u001b[39m, in \u001b[36m_\u001b[39m\u001b[34m(A, blocksize, quant_type, quant_storage)\u001b[39m\n\u001b[32m    247\u001b[39m     scaled = torch.cat([scaled, scaled_rem], dim=\u001b[32m0\u001b[39m)\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# Quantize with the lookup table\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m code = \u001b[43mCODE\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.to(scaled.dtype)\n\u001b[32m    251\u001b[39m quantized = torch.argmin(torch.abs(scaled.view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m) - code), dim=-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m).to(torch.uint8)\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Pack two quantized values per byte\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# quantization settings\n",
        "quantization_configs = BitsAndBytesConfig(\n",
        "  load_in_4bit=True,\n",
        "  bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "  bnb_4bit_quant_type='nf4',\n",
        "  bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "# device = \"\"\n",
        "# if torch.cuda.is_available():\n",
        "#   device = torch.device(\"cuda\")\n",
        "# elif torch.backends.mps.is_available():\n",
        "#   device = torch.device(\"mps\")\n",
        "# else:\n",
        "#   device = torch.device(\"cpu\")\n",
        "\n",
        "torch.device(\"mps\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  model_id,\n",
        "  attn_implementation=\"sdpa\",\n",
        "  quantization_config=quantization_configs,\n",
        "  device_map=\"auto\",\n",
        "  trust_remote_code=True,\n",
        "  use_safetensors=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "prompts = [\n",
        "  \"if (5x - 10) = 2, solve for x\",\n",
        "  \"if x = [1 0 2] and y = [0 1 0] find x^T y\",\n",
        "  r\"\"\"\n",
        "**Advanced Linear Algebra â€” Singular Value Decomposition (SVD) Computation**\n",
        "Let\n",
        "\\[\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "4 & 0 & 2 \\\\\n",
        "1 & 3 & 1 \\\\\n",
        "0 & 2 & 2\n",
        "\\end{bmatrix}.\n",
        "\\]\n",
        "\n",
        "Compute the full Singular Value Decomposition of \\(A\\). That is, determine orthogonal matrices \\(U \\in \\mathbb{R}^{3 \\times 3}\\) and \\(V \\in \\mathbb{R}^{3 \\times 3}\\), along with a diagonal matrix \\(\\Sigma \\in \\mathbb{R}^{3 \\times 3}\\) with non-negative entries, such that\n",
        "\n",
        "\\[\n",
        "A = U \\Sigma V^\\top.\n",
        "\\]\n",
        "\n",
        "Your computation must proceed from first principles: derive the singular values via the eigenvalues of \\(A^\\top A\\), construct \\(V\\) from the corresponding orthonormal eigenvectors, compute \\(U\\) using \\(U = A V \\Sigma^{-1}\\), and explicitly verify the decomposition by matrix multiplication. Finally, use the SVD to determine the rank and 2-norm condition number of \\(A\\).\n",
        "\"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXyjg6kjguvS"
      },
      "outputs": [],
      "source": [
        "# inputs = [tokenizer(prompt, return_tensors='pt').to('cuda') for prompt in prompts]\n",
        "# outputs = model.generate(**inputs[-1], max_new_tokens=1500, streamer=streamer, return_dict_in_generate=True)\n",
        "# response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "# parse chain-of-thought tokens\n",
        "\n",
        "def process_response(response):\n",
        "  reason_start = response.find('<think>') + len('<think>')\n",
        "  reason_end = response.find('</think>')\n",
        "  reason = response[reason_start:reason_end].strip()\n",
        "\n",
        "  # output\n",
        "  output_start = reason_end + len('</think>')\n",
        "  output = response[output_start:].strip()\n",
        "\n",
        "  return reason, output\n",
        "\n",
        "# reason, output = process_response(response)\n",
        "# print_markdown(f\"**Reasoning**: {reason}\")\n",
        "# print_markdown(f\"**Output**: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Vision + Audio capabilities to DeepSeek-R1 Distilled (and learn ONNX runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9e18a9f345046f2b6692e9407754dc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The image processor of type `ViTImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e540b65dfe2740da94dca9d675288b09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57e090b287334449b8de446b98e63d07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cancellation requested; stopping current tasks.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:588\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, tqdm_class, _tqdm_bar)\u001b[39m\n\u001b[32m    586\u001b[39m     progress.update(progress_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m vision_model_id = \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/swin-tiny-patch4-window7-224\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m processor = AutoImageProcessor.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mmicrosoft/swin-tiny-patch4-window7-224\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vision_model = \u001b[43mAutoModelForImageClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/swin-tiny-patch4-window7-224\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# print vision_model hidden layer\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVision model hidden layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvision_model.config.hidden_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:374\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    373\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    378\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    380\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/modeling_utils.py:3987\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3982\u001b[39m     logger.warning_once(\n\u001b[32m   3983\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA kernel_config was provided but use_kernels is False; setting use_kernels=True automatically. To suppress this warning, explicitly set use_kernels to True.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3984\u001b[39m     )\n\u001b[32m   3985\u001b[39m     use_kernels = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3987\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_kwargs_with_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransformers_weights\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3998\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gguf_file:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/modeling_utils.py:618\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, variant, gguf_file, use_safetensors, user_agent, is_remote_code, transformers_explicit_filename, download_kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m can_auto_convert = (\n\u001b[32m    607\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m is_offline_mode()  \u001b[38;5;66;03m# for obvious reasons\u001b[39;00m\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# If we are in a CI environment or in a pytest run, we prevent the conversion\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    611\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m subfolder == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# converter bot does not work on subfolders\u001b[39;00m\n\u001b[32m    612\u001b[39m )\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m    616\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;66;03m# Try safetensors files first if not already found\u001b[39;00m\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[32m    622\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/utils/hub.py:276\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    222\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m | os.PathLike,\n\u001b[32m    223\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    224\u001b[39m     **kwargs,\n\u001b[32m    225\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    226\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    228\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/transformers/utils/hub.py:419\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    418\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    433\u001b[39m         snapshot_download(\n\u001b[32m    434\u001b[39m             path_or_repo_id,\n\u001b[32m    435\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    444\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1024\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1003\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m   1004\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m   1005\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m         dry_run=dry_run,\n\u001b[32m   1022\u001b[39m     )\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1240\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1237\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1253\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1864\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, headers, expected_size, filename, force_download, etag, xet_file_data, tqdm_class)\u001b[39m\n\u001b[32m   1862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[32m   1863\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1864\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1871\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1872\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:583\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, tqdm_class, _tqdm_bar)\u001b[39m\n\u001b[32m    571\u001b[39m     displayed_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(â€¦)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    573\u001b[39m progress_cm = _get_progress_bar_context(\n\u001b[32m    574\u001b[39m     desc=displayed_filename,\n\u001b[32m    575\u001b[39m     log_level=logger.getEffectiveLevel(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    580\u001b[39m     _tqdm_bar=_tqdm_bar,\n\u001b[32m    581\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[32m    586\u001b[39m         progress.update(progress_bytes)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/std.py:1138\u001b[39m, in \u001b[36mtqdm.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# right now, take a tiny vision model, train it\n",
        "# create a projection --> DeepSeek\n",
        "vision_model_id = \"microsoft/swin-tiny-patch4-window7-224\"\n",
        "processor = AutoImageProcessor.from_pretrained(vision_model_id)\n",
        "vision_model = AutoModelForImageClassification.from_pretrained(vision_model_id, use_safetensors=True)\n",
        "# print vision_model hidden layer\n",
        "print(f\"Vision model hidden layer: {vision_model.config.hidden_size}\")\n",
        "print(f\"LLM hidden layer: {model.config.hidden_size}\")\n",
        "\n",
        "embedding_layer = model.get_input_embeddings()\n",
        "print(f\"Embedding Layer Weight Shape: {embedding_layer}\")\n",
        "print(50*'-')\n",
        "print(model)\n",
        "print(50*\"-\")\n",
        "print(\"ViT architecture\")\n",
        "print(vision_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"../data/images/dog.jpg\"\n",
        "img = Image.open(filename).convert(\"RGB\")\n",
        "img_input = processor(images=img, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    outputs = vision_model(**img_input)\n",
        "    print(f\"OUTPUT SHAPE: {outputs.logits}, hidden_layer: {outputs.logits[:,1:,:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RKnFSRs-IK2"
      },
      "source": [
        "### Let's fine-tune Deepseek-R1-Qwen 1.5 b on math & physics problems\n",
        "\n",
        "Datasets:\n",
        "\n",
        "<b>Math</b>\n",
        "```{python}\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"math-ai/StackMathQA\", \"stackmathqa1600k\") # or any valid config_name\n",
        "```\n",
        "\n",
        "<b> General 'science' datasets </b>\n",
        "<li> Scibench </li>\n",
        "<li> Others </li>\n",
        "\n",
        "```{python}\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_names = [('xw27/scibench', 'xw27/scibench'), (name, config)]\n",
        "for ds_name, config_name in dataset_names:\n",
        "  ds = load_dataset(ds_name, config_name)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "7c93676aa71344dd9a008bf3bf0abfe2",
            "7122f6f376c444bea1bfa0c363bbed11",
            "26e199ed4786476f8ef177e46cd6b0b8",
            "fbd520decd8f42c2add8a023e500be14",
            "6931691cb5b6448cb4d507dd8a95adaf",
            "b2b427aeccc04d54aece405fde777edf",
            "65883bf052724088b766cf4f924d8219",
            "568b6989eaa54553aba024b13bd270c2",
            "2a1fcf10a70e413d8f470654c7122c9d",
            "238aaa244b184cb18c1d8d743d2f0e00",
            "b06155a627b346e1add53a8ec10131ab"
          ]
        },
        "id": "CnjHrvL4-QfF",
        "outputId": "7e38160b-9fd0-47cc-d375-a70b9add36a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading mathllm/MathCodeInstruct...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function tqdm.__del__ at 0x109987e20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
            "    self.close()\n",
            "  File \"/Users/thorbthorb/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
            "    if self.disable:\n",
            "AttributeError: 'tqdm' object has no attribute 'disable'\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:657\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'https://huggingface.co/datasets/MathLLMs/MathCodeInstruct/resolve/eb858ec9141f6cc28f9e91429538fbda9db2be1e/MathCodeInstruct.py'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRemoteEntryNotFoundError\u001b[39m                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/load.py:985\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m985\u001b[39m     \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset scripts are no longer supported, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/hf_api.py:5608\u001b[39m, in \u001b[36mHfApi.hf_hub_download\u001b[39m\u001b[34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, etag_timeout, token, local_files_only, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   5606\u001b[39m     token = \u001b[38;5;28mself\u001b[39m.token\n\u001b[32m-> \u001b[39m\u001b[32m5608\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5619\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5621\u001b[39m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1024\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1099\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1099\u001b[39m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[32m   1114\u001b[39m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[32m   1115\u001b[39m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1121\u001b[39m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[32m   1122\u001b[39m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1691\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder, retry_on_errors)\u001b[39m\n\u001b[32m   1690\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1691\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RemoteEntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:1614\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, timeout, library_name, library_version, user_agent, headers, endpoint, retry_on_errors)\u001b[39m\n\u001b[32m   1613\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m response = \u001b[43m_httpx_follow_relative_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_errors\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1617\u001b[39m hf_raise_for_status(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_httpx_follow_relative_redirects\u001b[39m\u001b[34m(method, url, retry_on_errors, **httpx_kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m response = http_backoff(\n\u001b[32m    303\u001b[39m     method=method,\n\u001b[32m    304\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m     **no_retry_kwargs,\n\u001b[32m    308\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# Check if response is a relative redirect\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:671\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    670\u001b[39m     message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RemoteEntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_code == \u001b[33m\"\u001b[39m\u001b[33mGatedRepo\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[31mRemoteEntryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-698c1d25-2c81d6c41411575a349a9954;7755d131-6469-4f9b-aae7-890300b5e119)\n\nEntry Not Found for url: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct/resolve/eb858ec9141f6cc28f9e91429538fbda9db2be1e/MathCodeInstruct.py.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading mathllm/MathCodeInstruct...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m math_dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmathllm/MathCodeInstruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m math_dataset.take(\u001b[32m15000\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading xw27/scibench...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/load.py:1488\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1483\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   1484\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   1485\u001b[39m )\n\u001b[32m   1487\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/load.py:1133\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1132\u001b[39m     features = _fix_for_backward_compatible_features(features)\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[32m   1143\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/load.py:1007\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m    997\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    998\u001b[39m         use_exported_dataset_infos = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1009\u001b[39m     message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is a gated dataset on the Hub.\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/load.py:634\u001b[39m, in \u001b[36mHubDatasetModuleFactory.get_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    633\u001b[39m     patterns = get_data_patterns(base_path, download_config=\u001b[38;5;28mself\u001b[39m.download_config)\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m data_files = \u001b[43mDataFilesDict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m module_name, default_builder_kwargs = infer_module_for_data_files(\n\u001b[32m    641\u001b[39m     data_files=data_files,\n\u001b[32m    642\u001b[39m     path=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    643\u001b[39m     download_config=\u001b[38;5;28mself\u001b[39m.download_config,\n\u001b[32m    644\u001b[39m )\n\u001b[32m    645\u001b[39m data_files = data_files.filter(\n\u001b[32m    646\u001b[39m     extensions=_MODULE_TO_EXTENSIONS[module_name] + _MODULE_TO_METADATA_EXTENSIONS[module_name],\n\u001b[32m    647\u001b[39m     file_names=_MODULE_TO_METADATA_FILE_NAMES[module_name],\n\u001b[32m    648\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/data_files.py:708\u001b[39m, in \u001b[36mDataFilesDict.from_patterns\u001b[39m\u001b[34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[39m\n\u001b[32m    703\u001b[39m out = \u001b[38;5;28mcls\u001b[39m()\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns.items():\n\u001b[32m    705\u001b[39m     out[key] = (\n\u001b[32m    706\u001b[39m         patterns_for_key\n\u001b[32m    707\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m     )\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/data_files.py:611\u001b[39m, in \u001b[36mDataFilesList.from_patterns\u001b[39m\u001b[34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n\u001b[32m    610\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m origin_metadata = \u001b[43m_get_origin_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data_files, origin_metadata)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/datasets/data_files.py:518\u001b[39m, in \u001b[36m_get_origin_metadata\u001b[39m\u001b[34m(data_files, download_config, max_workers)\u001b[39m\n\u001b[32m    512\u001b[39m max_workers = max_workers \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m config.HF_DATASETS_MULTITHREADING_MAX_WORKERS\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mhf://\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data_file \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m data_files):\n\u001b[32m    514\u001b[39m     \u001b[38;5;66;03m# No need for multithreading here since the origin metadata of HF files\u001b[39;00m\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# is (repo_id, revision) and is cached after first .info() call.\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    517\u001b[39m         _get_single_origin_metadata(data_file, download_config=download_config)\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhf_tqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mResolving data files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# set `disable=None` rather than `disable=False` by default to disable progress bar when no TTY attached\u001b[39;49;00m\n\u001b[32m    522\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     ]\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[32m    526\u001b[39m     partial(_get_single_origin_metadata, download_config=download_config),\n\u001b[32m    527\u001b[39m     data_files,\n\u001b[32m   (...)\u001b[39m\u001b[32m    532\u001b[39m     disable=\u001b[38;5;28mlen\u001b[39m(data_files) <= \u001b[32m16\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    533\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/std.py:665\u001b[39m, in \u001b[36mtqdm.__new__\u001b[39m\u001b[34m(cls, *_, **__)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *_, **__):\n\u001b[32m    664\u001b[39m     instance = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# also constructs lock if non-existent\u001b[39;49;00m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_instances\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# create monitoring thread\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/std.py:111\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/jupyterfix/lib/python3.13/site-packages/tqdm/std.py:104\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.acquire\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, *a, **k):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.locks:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "# Load datasets\n",
        "print(\"Loading mathllm/MathCodeInstruct...\")\n",
        "math_dataset = load_dataset(\"mathllm/MathCodeInstruct\", split=\"train\", streaming=True)\n",
        "math_dataset.take(15000)\n",
        "\n",
        "print(\"Loading xw27/scibench...\")\n",
        "scibench_dataset = load_dataset(\"xw27/scibench\", split=\"train\", streaming=True)\n",
        "scibench_dataset.take(15000)\n",
        "\n",
        "# Display dataset sizes\n",
        "print(f\"\\nOriginal dataset sizes:\")\n",
        "print(f\"  MathCodeInstruct: {len(math_dataset):,} examples\")\n",
        "print(f\"  SciBench: {len(scibench_dataset):,} examples\")\n",
        "\n",
        "# Calculate sampling to get ~25k total examples\n",
        "# Allocate 60% to MathCodeInstruct (for tool-calling) and 40% to SciBench (for science)\n",
        "max_total = 25000\n",
        "math_samples = min(len(math_dataset), int(max_total * 0.6))  # 15k for tool-calling & math\n",
        "scibench_samples = min(len(scibench_dataset), max_total - math_samples)  # ~10k for science\n",
        "\n",
        "# Sample from datasets\n",
        "print(f\"\\nSampling datasets to reach ~{max_total:,} examples...\")\n",
        "print(f\"  Target: {math_samples:,} from MathCodeInstruct (tool-calling & math)\")\n",
        "print(f\"  Target: {scibench_samples:,} from SciBench (science)\")\n",
        "\n",
        "math_subset = math_dataset.shuffle(seed=42).select(range(math_samples))\n",
        "scibench_subset = scibench_dataset.shuffle(seed=42).select(range(scibench_samples))\n",
        "\n",
        "# Combine datasets\n",
        "print(\"\\nCombining datasets...\")\n",
        "combined_dataset = concatenate_datasets([math_subset, scibench_subset])\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "combined_dataset = combined_dataset.shuffle(seed=42)\n",
        "\n",
        "print(f\"\\n Combined dataset created:\")\n",
        "print(f\"  Total examples: {len(combined_dataset):,}\")\n",
        "print(f\"  - From MathCodeInstruct (tool-calling & math): {math_samples:,} ({math_samples/len(combined_dataset)*100:.1f}%)\")\n",
        "print(f\"  - From SciBench (science): {scibench_samples:,} ({scibench_samples/len(combined_dataset)*100:.1f}%)\")\n",
        "print(f\"\\nDataset features: {combined_dataset.features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-xuIpyiEYIa"
      },
      "source": [
        "# Fine-Tuning Setup\n",
        "\n",
        "Now we'll fine-tune DeepSeek-R1-Distill-Qwen-1.5B on our mixed math/science dataset using QLoRA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwNIjayUTsh5",
        "outputId": "492bf0bf-6d22-42c5-cd7b-4f01dfdb72d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "system: [{'type': 'text', 'content': 'Below is a math problem. Please solve it step by step.'}]\n",
            "\n",
            "user: [{'type': 'text', 'content': 'A soccer team has three goalies and ten defenders. The team also has twice as many midfielders as defenders, and the rest of the players are strikers. If the team has 40 players, how many strikers are in the team?'}]\n",
            "\n",
            "assistant: [{'type': 'code', 'content': '# Given:\\ngoalies = 3\\ndefenders = 10\\nmidfielders = 2 * defenders  # twice as many midfielders as defenders\\n\\n# Total players in the team is 40\\ntotal_players = 40\\n\\n# The rest of the players are strikers, so:\\nstrikers = total_players - (goalies + defenders + midfielders)\\nstrikers'}, {'type': 'execution', 'content': '7'}, {'type': 'text', 'content': 'The number of strikers in the team is \\\\(\\\\boxed{7}\\\\).'}, {'type': 'text', 'content': '7'}]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "first_item = combined_dataset[0]\n",
        "\n",
        "message = first_item[\"messages\"]\n",
        "for msg in message:\n",
        "  print(f\"{msg['role']}: {msg['content']}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW7uDaY0EYIa"
      },
      "outputs": [],
      "source": [
        "# Install fine-tuning dependencies\n",
        "!pip install -q -U \\\n",
        "    peft>=0.14.0 \\\n",
        "    trl>=0.12.0 \\\n",
        "    accelerate>=1.2.0 \\\n",
        "    scipy \\\n",
        "    tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGIB0zjoEYIb",
        "outputId": "f937b959-1107-44e1-f688-dd40fd0f0d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatting datasets to chat format with <think> reasoning tags...\n",
            "Formatting MathCodeInstruct...\n",
            "Formatting SciBench...\n",
            "  MathCodeInstruct: 15,000 valid examples\n",
            "  SciBench: 112 valid examples\n",
            "\n",
            "âœ“ Formatted dataset: 15,112 examples\n",
            "\n",
            "Example:\n",
            "{'messages': [{'content': '[{\\'type\\': \\'text\\', \\'content\\': \"Chloe bought chocolate-dipped strawberries at $50 a dozen. She then sold them for $30 for half a dozen during the Mother\\'s Day celebration. How much is Chloe\\'s profit if she sold 50 dozens?\"}]', 'role': 'user'}, {'content': \"<think>\\nAlright, let's break the problem down step-by-step:\\n\\n1. **Determine Chloe's expense for 1 dozen strawberries:**\\n   Chloe bought strawberries for $50 a dozen.\\n\\n2. **Determine Chloe's revenue from selling 1 dozen strawberries:**\\n   Chloe sells them for $30 for half a dozen. \\n   So, for 1 dozen, she would sell them for \\\\(2 \\\\times 30\\\\).\\n\\n3. **Determine Chloe's profit for 1 dozen strawberries:**\\n   Profit for 1 dozen = Revenue from 1 dozen - Expense for 1 dozen \\n\\n4. **Determine Chloe's profit for 50 dozens:**\\n   Total profit = 50 x Profit for 1 dozen\\n\\nNow, let's calculate these step-by-step.\\n<code>\\n# 1. Determine Chloe's expense for 1 dozen strawberries\\nexpense_per_dozen = 50\\n\\n# 2. Determine Chloe's revenue from selling 1 dozen strawberries\\nrevenue_per_half_dozen = 30\\nrevenue_per_dozen = 2 * revenue_per_half_dozen\\n\\n# 3. Determine Chloe's profit for 1 dozen strawberries\\nprofit_per_dozen = revenue_per_dozen - expense_per_dozen\\n\\n# 4. Determine Chloe's profit for 50 dozens\\ntotal_profit = 50 * profit_per_dozen\\n\\ntotal_profit\\n</code>\\n500\\nChloe's profit for selling 50 dozens of chocolate-dipped strawberries is \\\\(\\\\boxed{\\\\$500}\\\\).\\n500\\n</think>\\n\\nThe solution is provided above.\", 'role': 'assistant'}]}\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset, concatenate_datasets\n",
        "\n",
        "def format_mathcodeinstruct(example):\n",
        "    \"\"\"Convert MathCodeInstruct to DeepSeek-R1 chat format with reasoning.\"\"\"\n",
        "    messages = example.get(\"messages\", [])\n",
        "    if not messages:\n",
        "        return None\n",
        "\n",
        "    user_msg = None\n",
        "    assistant_msg = None\n",
        "\n",
        "    for msg in messages:\n",
        "        if msg.get('role') == 'user':\n",
        "            user_msg = msg.get('content', '')\n",
        "        elif msg.get('role') == 'assistant':\n",
        "            assistant_msg = msg.get('content', '')\n",
        "\n",
        "    if not user_msg or not assistant_msg:\n",
        "        return None\n",
        "\n",
        "    formatted_string = \"\"\n",
        "    if isinstance(assistant_msg, list):\n",
        "        for block in assistant_msg:\n",
        "            if isinstance(block, dict):\n",
        "                if block.get('type') == 'code':\n",
        "                    formatted_string += f\"<code>\\n{block.get('content', '')}\\n</code>\\n\"\n",
        "                else:\n",
        "                    formatted_string += f\"{block.get('content', '')}\\n\"\n",
        "            else:\n",
        "                formatted_string += str(block) + \"\\n\"\n",
        "        formatted_string = f\"<think>\\n{formatted_string.strip()}\\n</think>\\n\\nThe solution is provided above.\"\n",
        "    else:\n",
        "        formatted_string = f\"<think>\\n{assistant_msg}\\n</think>\\n\\nThe solution is provided above.\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": str(user_msg)},\n",
        "            {\"role\": \"assistant\", \"content\": formatted_string}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def format_scibench(example):\n",
        "    \"\"\"Convert SciBench to DeepSeek-R1 chat format with reasoning.\"\"\"\n",
        "    problem = example.get('problem_text', '')\n",
        "    solution = example.get('solution', '')\n",
        "    answer = example.get('answer_latex', '')\n",
        "    unit = example.get('unit', '')\n",
        "\n",
        "    if not problem or not solution:\n",
        "        return None\n",
        "\n",
        "    final_answer = answer\n",
        "    if unit:\n",
        "        final_answer = f\"{answer} {unit}\"\n",
        "\n",
        "    formatted_response = f\"<think>\\n{solution}\\n</think>\\n\\nFinal Answer: {final_answer}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": str(problem)},\n",
        "            {\"role\": \"assistant\", \"content\": formatted_response}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"Formatting datasets to chat format with <think> reasoning tags...\")\n",
        "\n",
        "# Build lists directly â€” no .map(), no Arrow type issues\n",
        "print(\"Formatting MathCodeInstruct...\")\n",
        "math_rows = []\n",
        "for example in math_subset:\n",
        "    result = format_mathcodeinstruct(example)\n",
        "    if result is not None:\n",
        "        math_rows.append(result)\n",
        "\n",
        "print(\"Formatting SciBench...\")\n",
        "sci_rows = []\n",
        "for example in scibench_subset:\n",
        "    result = format_scibench(example)\n",
        "    if result is not None:\n",
        "        sci_rows.append(result)\n",
        "\n",
        "# Create datasets from consistent lists\n",
        "math_formatted = Dataset.from_list(math_rows)\n",
        "scibench_formatted = Dataset.from_list(sci_rows)\n",
        "\n",
        "print(f\"  MathCodeInstruct: {len(math_formatted):,} valid examples\")\n",
        "print(f\"  SciBench: {len(scibench_formatted):,} valid examples\")\n",
        "\n",
        "# Combine and shuffle\n",
        "formatted_dataset = concatenate_datasets([math_formatted, scibench_formatted])\n",
        "formatted_dataset = formatted_dataset.shuffle(seed=42)\n",
        "\n",
        "print(f\"\\n Formatted dataset: {len(formatted_dataset):,} examples\")\n",
        "print(\"\\nExample:\")\n",
        "print(formatted_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnoTAMMFEYIb",
        "outputId": "22848317-af3e-43ff-b9f2-202a7cda58aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating train/eval split (90/10)...\n",
            "\n",
            "âœ“ Split complete:\n",
            "  Training examples: 13,600\n",
            "  Evaluation examples: 1,512\n"
          ]
        }
      ],
      "source": [
        "# Create 90/10 train/eval split\n",
        "print(\"Creating train/eval split (90/10)...\")\n",
        "split_dataset = formatted_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "train_dataset = split_dataset['train']\n",
        "eval_dataset = split_dataset['test']\n",
        "\n",
        "print(f\"\\nâœ“ Split complete:\")\n",
        "print(f\"  Training examples: {len(train_dataset):,}\")\n",
        "print(f\"  Evaluation examples: {len(eval_dataset):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAj6Jk8oEYIb",
        "outputId": "629770c1-fe39-464c-e369-b9a2962360a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded\n"
          ]
        }
      ],
      "source": [
        "# Load model for fine-tuning with QLoRA\n",
        "from peft import (\n",
        "    prepare_model_for_kbit_training,\n",
        "    LoraConfig,\n",
        "    get_peft_model\n",
        ")\n",
        "\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.padding_side = \"right\"  # Important for training\n",
        "  model.config.pad_token_id = tokenizer.pad_token\n",
        "\n",
        "# Prepare model for k-bit training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# LoRA version\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CASUAL_LM\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# tokenize dataset?\n",
        "def tokenize(examples):\n",
        "  return tokenizer.apply_chat_template(\n",
        "      examples[\"messages\"],\n",
        "      truncation=True\n",
        "      )\n",
        "\n",
        "tokenized_training_dataset = train_dataset.map(\n",
        "    tokenize,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "\n",
        "tokenized_eval_dataset = test_dataset.map(\n",
        "    tokenize,\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer, mlm=False\n",
        ") # next-token prediction\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./deepseek-r1-math-science-lora-fine-tuning\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,\n",
        "    max_steps=-1, # -1 value ensures that it follows the number of training epochs param\n",
        "\n",
        "    # batch configs\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    gradient_checkpointing=True,\n",
        "\n",
        "    # learning rate configs\n",
        "    learning_rate=2e-4, # generally 5e-5 for full fine-tuning\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.10,\n",
        "\n",
        "    # optimization configs\n",
        "    optim=\"paged_adamw_8bit\", # memory efficient, adamw_torch_fused is fastest\n",
        "    weight_decay=0.1,\n",
        "    max_grad_norm=0.1,\n",
        "\n",
        "    # eval configs\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "\n",
        "    # saving configs\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=3,\n",
        "\n",
        "    # Logging configs\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    logging_first_step=True,\n",
        "\n",
        "    # performance configs\n",
        "    fp16=True,\n",
        "    dataloader_num_workers=4,\n",
        "    dataloader_pin_memory=True,\n",
        "\n",
        "    # Misc\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "# initialize trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_training_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# train\n",
        "print(\"TRAINING STARTED\")\n",
        "trainer.train()\n",
        "print(\"TRAINING COMPLETE\")\n",
        "\n",
        "\n",
        "# save model\n",
        "output_path = \"./deepseek-r1-math-science-full-fine-tuning\"\n",
        "trainer.save_model(output_path)\n",
        "tokenizer.save_pretrained(output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlkQRru9EYId"
      },
      "source": [
        "# Testing Fine-Tuned Model\n",
        "\n",
        "Let's test the fine-tuned model on some math and science problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRv570T2EYId"
      },
      "source": [
        "# Merge LoRA Adapters with Base Model\n",
        "\n",
        "For deployment, you can merge the LoRA adapters with the base model to create a standalone model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfvKmd-oEYId"
      },
      "outputs": [],
      "source": [
        "# Optional: Merge LoRA adapters with base model for deployment\n",
        "print(\"Merging LoRA adapters with base model...\")\n",
        "print(\"This creates a standalone model (~3GB) that doesn't require PEFT.\\n\")\n",
        "\n",
        "# Reload base model in fp16 (not quantized) for merging\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load base model in fp16\n",
        "merge_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# Load LoRA adapters\n",
        "merge_model = PeftModel.from_pretrained(merge_model, output_path)\n",
        "\n",
        "# Merge adapters into base model\n",
        "merged_model = merge_model.merge_and_unload()\n",
        "\n",
        "# Save merged model\n",
        "merged_output_path = \"./deepseek-r1-math-science-merged\"\n",
        "merged_model.save_pretrained(merged_output_path)\n",
        "tokenizer.save_pretrained(merged_output_path)\n",
        "\n",
        "print(f\"\\n Merged model saved to {merged_output_path}\")\n",
        "print(f\"  Size: ~3GB\")\n",
        "print(f\"\\nYou can now convert this to GGUF for on-device deployment using llama.cpp.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob25kI09IoD1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PvFm9mXnK7F"
      },
      "source": [
        "# Visualise Attention\n",
        "\n",
        "<p> Use TinyBERT & visualizew the self attention mechanism </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNvrrpJvnWqX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "from bertviz import head_view, model_view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mzLnFHxngwK"
      },
      "outputs": [],
      "source": [
        "model=AutoModel.from_pretrained(\"prajjwal1/bert-tiny\", output_attentions=True)\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "\n",
        "prompt = \"John's dog ate Nemis's cat\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L7oX0JwinVz"
      },
      "source": [
        "# Stop doing this blindly:\n",
        "model = AutoModelForCausalLM.from_pretrained(\"model\")\n",
        "\n",
        "#### Start understanding:\n",
        "#### - What are attention heads doing?\n",
        "#### - How does positional encoding work?\n",
        "#### - What's the difference between encoder-only (BERT), decoder-only (GPT), encoder-decoder (T5)?\n",
        "#### - Why does model size scale quadratically with context length?\n",
        "\n",
        "Action items:\n",
        "\n",
        "Read \"Attention Is All You Need\" paper (seriously)\n",
        "Implement a mini-transformer from scratch (100-200 lines)\n",
        "Use model.generate(output_attentions=True) to visualize what the model \"sees\"\n",
        "Study the HuggingFace modeling_*.py source code for your favorite models\n",
        "Resources:\n",
        "\n",
        "Andrej Karpathy's \"Neural Networks: Zero to Hero\" (YouTube)\n",
        "Jay Alammar's \"Illustrated Transformer\" blog\n",
        "HuggingFace Transformers source code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfssHiGupxVU"
      },
      "source": [
        "#### Bootcamp level:\n",
        "model = AutoModelForCausalLM.from_pretrained(\"model\", load_in_4bit=True)\n",
        "\n",
        "#### Production level:\n",
        "#### - Batching multiple requests efficiently\n",
        "#### - KV-cache optimization for faster inference\n",
        "#### - Flash Attention for 2-4x speedups\n",
        "#### - ONNX/TensorRT conversion for production serving\n",
        "#### - Model distillation to create smaller models\n",
        "#### - Prompt caching to reduce redundant computation\n",
        "\n",
        "Learn:\n",
        "\n",
        "vLLM / Text Generation Inference (TGI): Production inference servers\n",
        "GGML/llama.cpp: CPU-optimized inference\n",
        "Triton Inference Server: Multi-model deployment\n",
        "Batch processing: Processing 100 requests > processing 1 request 100 times\n",
        "Continuous batching: Dynamic batching as requests arrive\n",
        "Metrics that matter:\n",
        "\n",
        "Throughput (tokens/second)\n",
        "Latency (time to first token, time per token)\n",
        "Cost per 1M tokens\n",
        "GPU utilization %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7Wxuf6Yip-H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyterfix",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "238aaa244b184cb18c1d8d743d2f0e00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e199ed4786476f8ef177e46cd6b0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_568b6989eaa54553aba024b13bd270c2",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a1fcf10a70e413d8f470654c7122c9d",
            "value": 20
          }
        },
        "2a1fcf10a70e413d8f470654c7122c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45512218c0954f0cb9547bf00dc494f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "568b6989eaa54553aba024b13bd270c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65883bf052724088b766cf4f924d8219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6931691cb5b6448cb4d507dd8a95adaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2f0b6757254b0ebb316a7786943476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7122f6f376c444bea1bfa0c363bbed11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b427aeccc04d54aece405fde777edf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_65883bf052724088b766cf4f924d8219",
            "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
          }
        },
        "7234d0f46f8a43a194c542f5446b4e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d2f0b6757254b0ebb316a7786943476",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c970f6cdb0054e69bd86b4cb1987bafd",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "7c93676aa71344dd9a008bf3bf0abfe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7122f6f376c444bea1bfa0c363bbed11",
              "IPY_MODEL_26e199ed4786476f8ef177e46cd6b0b8",
              "IPY_MODEL_fbd520decd8f42c2add8a023e500be14"
            ],
            "layout": "IPY_MODEL_6931691cb5b6448cb4d507dd8a95adaf"
          }
        },
        "8a6ab6f09b8840a9b9bbfd895fd99f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998b2556aced48aba9ab08bb76f2e166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7234d0f46f8a43a194c542f5446b4e6a",
              "IPY_MODEL_9ac1a8b1bb264fc3b438a3984ed1a72e",
              "IPY_MODEL_daadc7677b244b15a8f36db5fd9f31ae"
            ],
            "layout": "IPY_MODEL_cdbc42c8132046f69c87c2e64aa496a1"
          }
        },
        "9ac1a8b1bb264fc3b438a3984ed1a72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d2dcc08a374677857f24b3dae098a6",
            "max": 339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45512218c0954f0cb9547bf00dc494f6",
            "value": 339
          }
        },
        "a4acb11c7c9548fab831a42cf0117d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b06155a627b346e1add53a8ec10131ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2b427aeccc04d54aece405fde777edf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d2dcc08a374677857f24b3dae098a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c970f6cdb0054e69bd86b4cb1987bafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdbc42c8132046f69c87c2e64aa496a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daadc7677b244b15a8f36db5fd9f31ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6ab6f09b8840a9b9bbfd895fd99f3a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a4acb11c7c9548fab831a42cf0117d8e",
            "value": "â€‡339/339â€‡[00:00&lt;00:00,â€‡741.79it/s,â€‡Materializingâ€‡param=model.norm.weight]"
          }
        },
        "fbd520decd8f42c2add8a023e500be14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_238aaa244b184cb18c1d8d743d2f0e00",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b06155a627b346e1add53a8ec10131ab",
            "value": "â€‡20/20â€‡[00:00&lt;00:00,â€‡3907.68it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
